import sounddevice as sd
import numpy as np
import whisper
import librosa
import threading
import queue
import os
import tkinter as tk
from tkinter import messagebox

# ----- è¨­å®šé …ç›® -----
RECORD_SEC = 5            # 5ç§’ã”ã¨ã®åˆ†å‰²éŒ²éŸ³
BUFFER_SEC = 60           # 60ç§’åˆ†è²¯ã¾ã£ãŸã‚‰ã‚­ãƒ¥ãƒ¼ã«é€ã‚‹
SAMPLE_RATE = 48000       # éŒ²éŸ³æ™‚ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
TARGET_SR = 16000         # Whisperç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
NUM_CHANNEL = 3
VOLUME = 1.3
MODEL_SIZE = "medium"     # whisperãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
SD_DEVICE = "mojiokoshi"  # spotæ¤œç´¢ã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®šã‹ã‚‰å¤‰æ›´å¯èƒ½
LANGUAGE = "ja"          # Whisperã®è¨€èªè¨­å®šï¼ˆä¾‹: "ja"ã€"en"ï¼‰

class MojiOkoshi:
    def __init__(self):
        print(f"Whisperãƒ¢ãƒ‡ãƒ«({MODEL_SIZE})ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        self.model = whisper.load_model(MODEL_SIZE)
        print("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

        self.audio_queue = queue.Queue()
        self.text_results = []
        self.stop_flag = threading.Event()
        self.thread = None
        self.current_scene = "default"
        self.scene_transcriptions = {}
        self.transcription_lock = threading.Lock() 
        self.scenes = {}
        
        
        # æœªå®Œæˆã®éŒ²éŸ³ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä¿æŒã™ã‚‹ãƒãƒƒãƒ•ã‚¡
        self.partial_audio_buffer = []
        self.blocksize = int(RECORD_SEC * SAMPLE_RATE)  # 1ç§’åˆ†ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
        self.buffer_target_size = int(BUFFER_SEC * SAMPLE_RATE)  # 60ç§’åˆ†ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
        
        # å‡¦ç†é€²è¡ŒçŠ¶æ³ã®è¿½è·¡
        self.processing_progress = {
            'total_items': 0,
            'processed_items': 0,
            'current_stage': 'idle'  # idle, transcribing, saving, completed
        }


    def audio_callback(self, indata, frames, time_info, status):
        if self.stop_flag.is_set():
            return
        if status:
            print(f"audio_callback status: {status}")
        #print(f" ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {indata.shape}, ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frames}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        self.partial_audio_buffer.append(indata.copy())
        
        # ãƒãƒƒãƒ•ã‚¡ãŒ60ç§’åˆ†ï¼ˆbuffer_target_sizeï¼‰ã«é”ã—ãŸã‚‰ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        total_frames = sum(data.shape[0] for data in self.partial_audio_buffer)
        if total_frames >= self.buffer_target_size:
            # ãƒãƒƒãƒ•ã‚¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            combined_data = np.concatenate(self.partial_audio_buffer, axis=0)
            self.audio_queue.put(combined_data)
            print(f"60ç§’åˆ†ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ  - ç¾åœ¨ã®ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º: {self.audio_queue.qsize()}")
            # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
            self.partial_audio_buffer = []
        # else:
        #     print(f"DEBUG: ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è“„ç©ä¸­ - ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}/{self.buffer_target_size} ({total_frames/self.buffer_target_size*100:.1f}%)")

    def transcribe_worker(self):
        processed_index = 0
        #print("DEBUG: transcribe_workeré–‹å§‹")
        while not self.stop_flag.is_set() or not self.audio_queue.empty() or self.partial_audio_buffer:
            #print(f"DEBUG: ãƒ«ãƒ¼ãƒ—é–‹å§‹ - stop_flag: {self.stop_flag.is_set()}, queue_empty: {self.audio_queue.empty()}, buffer_empty: {len(self.partial_audio_buffer) == 0}")
            try:
                # stop_flagãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯çŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§å¾…æ©Ÿ
                timeout = 0.5 if self.stop_flag.is_set() else 1.0
                #print("DEBUG: ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
                data = self.audio_queue.get(timeout=timeout)
                #print("DEBUG: ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ")
                try:
                    processed_index += 1
                    total_queue = processed_index + self.audio_queue.qsize()
                    print(f"å‡¦ç†é–‹å§‹ ({processed_index} / {total_queue})")

                    # ãƒ¢ãƒãƒ©ãƒ«åŒ–
                    if data.ndim > 1:
                        mono = np.mean(data, axis=1)
                    else:
                        mono = data.flatten()

                    # ç©ºãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
                    if mono.size == 0:
                        text = "[éŸ³å£°ãªã—]"
                        #print("DEBUG: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã¾ã™ã€‚")
                        self.text_results.append(text)
                        self.add_transcription(text)
                        print(f"å‡¦ç†å®Œäº† ({processed_index} / {total_queue})")
                        continue

                    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    resampled = librosa.resample(mono, orig_sr=SAMPLE_RATE, target_sr=TARGET_SR)
                    resampled = np.clip(resampled * VOLUME, -1.0, 1.0)

                    # Whisperã§æ–‡å­—èµ·ã“ã—
                    #print(f"Whisperå‡¦ç†é–‹å§‹ ({processed_index} / {total_queue})")
                    try:
                        result = self.model.transcribe(resampled, language=LANGUAGE)
                        text = result["text"]
                        print(text)
                        self.text_results.append(text)
                        self.add_transcription(text)
                    except Exception as e:
                        #print(f"DEBUG: Whisperå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶™ç¶š
                        text = f"[æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...]"
                        self.text_results.append(text)
                        self.add_transcription(text)
                    print(f"å‡¦ç†å®Œäº† ({processed_index} / {total_queue})")
                finally:
                    self.audio_queue.task_done()
            except queue.Empty:
                #print("DEBUG: ã‚­ãƒ¥ãƒ¼ãŒç©ºï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰")
                # stop_flagãŒè¨­å®šã•ã‚Œã¦ã„ã¦ã€ã‚­ãƒ¥ãƒ¼ãŒç©ºã§ãƒãƒƒãƒ•ã‚¡ã‚‚ç©ºã®å ´åˆã¯çµ‚äº†
                if self.stop_flag.is_set() and self.audio_queue.empty() and len(self.partial_audio_buffer) == 0:
                    #print("DEBUG: stop_flagãŒè¨­å®šã•ã‚Œã¦ã„ã¦ã‚­ãƒ¥ãƒ¼ã¨ãƒãƒƒãƒ•ã‚¡ãŒç©ºãªã®ã§çµ‚äº†")
                    break
                continue
        #print("DEBUG: transcribe_workerçµ‚äº†")

    def start(self):
        #print("DEBUG: start()ãƒ¡ã‚½ãƒƒãƒ‰é–‹å§‹")
        
        # åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º
        #print("DEBUG: åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹:")
        # devices = sd.query_devices()
        # for i, device in enumerate(devices):
        #     print(f"  {i}: {device['name']} (å…¥åŠ›: {device['max_input_channels']}, å‡ºåŠ›: {device['max_output_channels']})")
        
        try:
            sd.default.device = SD_DEVICE  # BlackHole + ãƒã‚¤ã‚¯ã®è¤‡åˆãƒ‡ãƒã‚¤ã‚¹å
            sd.default.samplerate = SAMPLE_RATE
            sd.default.channels = NUM_CHANNEL  # ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³
            #print(f"DEBUG: éŒ²éŸ³è¨­å®š - ãƒ‡ãƒã‚¤ã‚¹: {SD_DEVICE}, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {SAMPLE_RATE}, ãƒãƒ£ãƒ³ãƒãƒ«: {NUM_CHANNEL}")

            # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã¯1ç§’åˆ†ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
            blocksize = int(RECORD_SEC * SAMPLE_RATE)
            #print(f"DEBUG: ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º: {blocksize} (1ç§’åˆ†)")

            self.stream = sd.InputStream(callback=self.audio_callback, blocksize=blocksize)
            self.stream.start()
            print(f"{RECORD_SEC}ç§’é–“éš”ã§éŒ²éŸ³é–‹å§‹...")
            #print("DEBUG: éŒ²éŸ³ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹å®Œäº†")

            self.thread = threading.Thread(target=self.transcribe_worker, daemon=True)
            self.thread.start()
            #print("DEBUG: transcribe_workerã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹")
        except Exception as e:
            print(f"éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def stop(self):
        print("\néŒ²éŸ³åœæ­¢ä¸­...")

        # 1. ã¾ãšéŒ²éŸ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã“ãªã„ã‚ˆã†ã«ã—ã¾ã™
        if hasattr(self, 'stream') and self.stream.active:
            self.stream.stop()
            self.stream.close()
            print("éŒ²éŸ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")

        # 2. ä¸­é€”åŠç«¯ã«æ®‹ã£ã¦ã„ã‚‹éŸ³å£°ãƒ‡ãƒ¼ã‚¿(ãƒãƒƒãƒ•ã‚¡)ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã—ã¾ã™
        # ã“ã‚ŒãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ç›´æ¥ã®åŸå› ã§ã™
        if self.partial_audio_buffer:
            print(f"æ®‹ã‚Šã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ ({sum(data.shape[0] for data in self.partial_audio_buffer)}ãƒ•ãƒ¬ãƒ¼ãƒ ) ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã—ã¾ã™ã€‚")
            combined_data = np.concatenate(self.partial_audio_buffer, axis=0)
            self.audio_queue.put(combined_data)
            self.partial_audio_buffer = [] # ãƒãƒƒãƒ•ã‚¡ã‚’ç©ºã«ã™ã‚‹

        # 3. ã‚­ãƒ¥ãƒ¼ãŒç©ºã«ãªã‚‹ã¾ã§ã€æ–‡å­—èµ·ã“ã—ã‚¹ãƒ¬ãƒƒãƒ‰ã«å‡¦ç†ã‚’ç¶šã‘ã•ã›ã¾ã™
        print("æ®‹ã‚Šã®æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’å¾…ã£ã¦ã„ã¾ã™...")
        # ã‚­ãƒ¥ãƒ¼ã®å…¨ã¦ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¤
        self.audio_queue.join()

        # 4. å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒçµ‚ã‚ã£ãŸã®ã§ã€ã‚¹ãƒ¬ãƒƒãƒ‰ã«åœæ­¢ä¿¡å·ã‚’é€ã‚Šã¾ã™
        self.stop_flag.set()
        #print("DEBUG: stop_flagã‚’è¨­å®šã—ã¾ã—ãŸã€‚")

        # 5. ã‚¹ãƒ¬ãƒƒãƒ‰ãŒå®‰å…¨ã«çµ‚äº†ã™ã‚‹ã®ã‚’å¾…ã¡ã¾ã™
        if self.thread is not None and self.thread.is_alive():
            print("æ–‡å­—èµ·ã“ã—ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿä¸­...")
            self.thread.join() # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ã§å¾…ã¤
            print("ã‚¹ãƒ¬ãƒƒãƒ‰ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸã€‚")

        # æ–‡å­—èµ·ã“ã—å®Œäº†
        self.update_progress('saving', self.processing_progress['total_items'], self.processing_progress['total_items'])
        print("éŒ²éŸ³åœæ­¢å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    def save(self, filename):
        with open(filename, "w", encoding="utf-8") as f:
            f.write("\n".join(self.text_results)) 
        print(f"æ–‡å­—èµ·ã“ã—çµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    def switch_scene(self, scene_title: str):
        """ç¾åœ¨ã®éŒ²éŸ³ã‚·ãƒ¼ãƒ³ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹"""
        if not scene_title:
            print("âš ï¸ ã‚·ãƒ¼ãƒ³åãŒç©ºã§ã™ã€‚")
            return False  # åˆ‡ã‚Šæ›¿ãˆä¸å¯

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if scene_title in self.scene_transcriptions:
            print(f"âš ï¸ ã‚·ãƒ¼ãƒ³å '{scene_title}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚åˆ¥ã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return False

        # â˜…å‰ã‚·ãƒ¼ãƒ³ã®æœªå‡¦ç†ãƒãƒƒãƒ•ã‚¡ã¨ã‚­ãƒ¥ãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§æ–‡å­—èµ·ã“ã—ã—ã¦åæ˜ 
        prev_scene = self.current_scene
        # Deep copy buffer and queue items for async processing
        # æœªå‡¦ç†ã®ãƒãƒƒãƒ•ã‚¡ã¨ã‚­ãƒ¥ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        old_buffer = self.partial_audio_buffer
        old_queue = self.audio_queue

        # æ–°ã—ã„ã‚­ãƒ¥ãƒ¼ã¨ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¢ãƒˆãƒŸãƒƒã‚¯ã«è¨­å®š
        self.partial_audio_buffer = []
        self.audio_queue = queue.Queue()
        
        # æ–°ã—ã„ã‚·ãƒ¼ãƒ³ã«åˆ‡ã‚Šæ›¿ãˆ
        self.current_scene = scene_title
        self.scene_transcriptions[scene_title] = []

        # å¤ã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã‚’é–‹å§‹
        if old_buffer or not old_queue.empty():
            queue_items = []
            while not old_queue.empty():
                try:
                    queue_items.append(old_queue.get_nowait())
                except queue.Empty:
                    break
            
            threading.Thread(
                target=self.process_scene_async,
                args=(prev_scene, old_buffer, queue_items),
                daemon=True
            ).start()
            print(f"ã‚·ãƒ¼ãƒ³ '{prev_scene}' ã®æœªå‡¦ç†ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å‡¦ç†é–‹å§‹ã€‚")

        print(f"\nğŸ¬ ã‚·ãƒ¼ãƒ³åˆ‡ã‚Šæ›¿ãˆ â†’ {scene_title}")
        return True

    def add_transcription(self, text: str):
        """æ–‡å­—èµ·ã“ã—çµæœã‚’ç¾åœ¨ã®ã‚·ãƒ¼ãƒ³ã«è¿½åŠ """
        if self.current_scene not in self.scene_transcriptions:
            self.scene_transcriptions[self.current_scene] = []
        self.scene_transcriptions[self.current_scene].append(text)
        print(f"ã‚·ãƒ¼ãƒ³ '{self.current_scene}' ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ : '{text[:50]}...'")
    
    def update_progress(self, stage: str, processed: int = None, total: int = None):
        """å‡¦ç†é€²è¡ŒçŠ¶æ³ã‚’æ›´æ–°"""
        self.processing_progress['current_stage'] = stage
        if processed is not None:
            self.processing_progress['processed_items'] = processed
        if total is not None:
            self.processing_progress['total_items'] = total
    
    def get_progress_percentage(self):
        """é€²è¡ŒçŠ¶æ³ã®ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’å–å¾—"""
        if self.processing_progress['total_items'] == 0:
            return 0
        return int((self.processing_progress['processed_items'] / self.processing_progress['total_items']) * 100)

    def save_all_scenes(self, output_dir=None):
        """
        å…¨ã‚·ãƒ¼ãƒ³ã®æ–‡å­—èµ·ã“ã—ã‚’ä¿å­˜
        - å„ã‚·ãƒ¼ãƒ³ã®.txtã‚’ log/output/ ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ä¿å­˜
        """
        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        if output_dir is None:
            output_dir = os.path.join("log", "output")
        os.makedirs(output_dir, exist_ok=True)
        self.scenes = {}

        for scene, texts in self.scene_transcriptions.items():
            # ç©ºã®ã‚·ãƒ¼ãƒ³ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã¾ãŸã¯ç©ºãƒªã‚¹ãƒˆï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
            clean_texts = [t for t in texts if t.strip()]  # ç©ºæ–‡å­—ã‚’é™¤å¤–
            if not clean_texts:
                print(f"ã‚·ãƒ¼ãƒ³ '{scene}' ã¯ç©ºãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
            safe_name = scene.replace("/", "_").replace("\\", "_")
            file_path = os.path.join(output_dir, f"{safe_name}.txt")
            with open(file_path, "w", encoding="utf-8") as f:
                f.write("\n".join(clean_texts))
            print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {file_path}")
            # scenesã«è¿½åŠ 
            self.scenes[scene] = "\n".join(clean_texts)

    @property
    def transcription(self):
        return "\n".join(self.text_results)
    
    def get_initial_scene_name(self, parent_window=None):
        """æœ€åˆã®ã‚·ãƒ¼ãƒ³åã‚’å…¥åŠ›ã™ã‚‹ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’è¡¨ç¤º"""
        # ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½œæˆ
        dialog = tk.Toplevel(parent_window) if parent_window else tk.Tk()
        dialog.title("ã‚·ãƒ¼ãƒ³åã‚’å…¥åŠ›")
        dialog.geometry("400x150")
        dialog.resizable(False, False)
        
        # ãƒ¡ã‚¤ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
        if parent_window:
            dialog.transient(parent_window)
            dialog.grab_set()
            # ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’ä¸­å¤®ã«é…ç½®
            dialog.geometry("+%d+%d" % (parent_window.winfo_rootx() + 50, parent_window.winfo_rooty() + 50))
        
        # ãƒ©ãƒ™ãƒ«
        label = tk.Label(dialog, text="æœ€åˆã®ã‚·ãƒ¼ãƒ³åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", font=("Arial", 12))
        label.pack(pady=20)
        
        # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        entry = tk.Entry(dialog, width=30, font=("Arial", 11))
        entry.pack(pady=10)
        entry.focus()  # ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚’è¨­å®š
        
        # ãƒœã‚¿ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        button_frame = tk.Frame(dialog)
        button_frame.pack(pady=10)
        
        result = {"scene_name": None}
        
        def on_ok():
            scene_name = entry.get().strip()
            if scene_name:
                result["scene_name"] = scene_name
                self.switch_scene(scene_name)
                dialog.destroy()
            else:
                messagebox.showwarning("è­¦å‘Š", "ã‚·ãƒ¼ãƒ³åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        def on_cancel():
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒ¼ãƒ³ã‚’ä½¿ç”¨
            result["scene_name"] = "default"
            self.switch_scene("default")
            dialog.destroy()
        
        # OKãƒœã‚¿ãƒ³
        ok_button = tk.Button(button_frame, text="OK", command=on_ok, width=10)
        ok_button.pack(side=tk.LEFT, padx=5)
        
        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³
        cancel_button = tk.Button(button_frame, text="ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ", command=on_cancel, width=10)
        cancel_button.pack(side=tk.LEFT, padx=5)
        
        # Enterã‚­ãƒ¼ã§OK
        entry.bind('<Return>', lambda e: on_ok())
        
        # Escapeã‚­ãƒ¼ã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        dialog.bind('<Escape>', lambda e: on_cancel())
        
        # ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ãŒé–‰ã˜ã‚‰ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
        if parent_window:
            dialog.wait_window()
        else:
            dialog.mainloop()
        
        return result["scene_name"]
    
    def save_combined_scenario(self, scenario_title, output_dir=None):
        """
        å…¨ã‚·ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ã¦1ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã€‚
        ã‚·ãƒ¼ãƒ³ã”ã¨ã«ãƒ˜ãƒƒãƒ€ã‚’ä»˜ã‘ã¦é€£çµã—ã€å„æ–‡ã”ã¨ã«é©åˆ‡ãªæ”¹è¡Œã‚’æŒ¿å…¥ã€‚
        - çµåˆãƒ†ã‚­ã‚¹ãƒˆã¯ log/scenario_log/ ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ä¿å­˜
        """
        if not self.scenes:
            print("DEBUG: scenesãŒç©ºã§ã™ã€‚save_all_scenes()ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
            return None

        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        if output_dir is None:
            output_dir = os.path.join("log", "scenario_log")
        os.makedirs(output_dir, exist_ok=True)
        safe_title = scenario_title.replace("/", "_").replace("\\", "_")
        combined_file_path = os.path.join(output_dir, f"{safe_title}.txt")

        sentence_terminators = ("ã€‚", "ï¼", ".", "!", "?")

        with open(combined_file_path, "w", encoding="utf-8") as f:
            for idx, (scene_name, text) in enumerate(self.scenes.items()):
                f.write(f"ã€{scene_name}ã€‘\n")
                # ã‚·ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡Œã”ã¨ã«åˆ†å‰²ã—ã€å„æ–‡æœ«ã§æ”¹è¡Œã‚’æŒ¿å…¥
                lines = text.splitlines()
                for line in lines:
                    line = line.rstrip()
                    if not line:
                        continue
                    f.write(line)
                    if line.endswith(sentence_terminators):
                        f.write("\n\n")
                    else:
                        f.write("\n")
                # ã‚·ãƒ¼ãƒ³é–“ã¯3ã¤ã®æ”¹è¡Œã§åŒºåˆ‡ã‚‹
                f.write("\n\n\n")

        print(f"å…¨ã‚·ãƒ¼ãƒ³çµåˆãƒ†ã‚­ã‚¹ãƒˆä¿å­˜å®Œäº†: {combined_file_path}")
        return combined_file_path
    
    def process_partial_buffer_for_scene(self):
        """ç¾åœ¨ã®ã‚·ãƒ¼ãƒ³ã«å¯¾ã—ã¦ã€æœªå‡¦ç†ãƒãƒƒãƒ•ã‚¡ã¨ã‚­ãƒ¥ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦è¿½åŠ """
        # ãƒãƒƒãƒ•ã‚¡ã‚’å‡¦ç†
        if self.partial_audio_buffer:
            combined_data = np.concatenate(self.partial_audio_buffer, axis=0)
            mono = np.mean(combined_data, axis=1) if combined_data.ndim > 1 else combined_data.flatten()
            if mono.size > 0:
                resampled = librosa.resample(mono, orig_sr=SAMPLE_RATE, target_sr=TARGET_SR)
                resampled = np.clip(resampled * 1.3, -1.0, 1.0)
                try:
                    result = self.model.transcribe(resampled, language=LANGUAGE)
                    text = result["text"]
                    self.add_transcription(text)
                except Exception as e:
                    text = f"[æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...]"
                    self.add_transcription(text)
            self.partial_audio_buffer = []

        # ã‚­ãƒ¥ãƒ¼ã‚’å‡¦ç†
        while not self.audio_queue.empty():
            try:
                data = self.audio_queue.get_nowait()
                mono = np.mean(data, axis=1) if data.ndim > 1 else data.flatten()
                if mono.size > 0:
                    resampled = librosa.resample(mono, orig_sr=SAMPLE_RATE, target_sr=TARGET_SR)
                    resampled = np.clip(resampled * 1.3, -1.0, 1.0)
                    try:
                        result = self.model.transcribe(resampled, language=LANGUAGE)
                        text = result["text"]
                        self.add_transcription(text)
                    except Exception as e:
                        text = f"[æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...]"
                        self.add_transcription(text)
                self.audio_queue.task_done()
            except queue.Empty:
                break
    def process_scene_async(self, scene_name, buffer_data, queue_data):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚·ãƒ¼ãƒ³ã®ãƒãƒƒãƒ•ã‚¡ã¨ã‚­ãƒ¥ãƒ¼ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦è¿½åŠ """
        texts_to_add = []
        
        # ãƒãƒƒãƒ•ã‚¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        if buffer_data:
            try:
                combined_data = np.concatenate(buffer_data, axis=0)
                mono = np.mean(combined_data, axis=1) if combined_data.ndim > 1 else combined_data.flatten()
                if mono.size > 0:
                    resampled = librosa.resample(mono, orig_sr=SAMPLE_RATE, target_sr=TARGET_SR)
                    resampled = np.clip(resampled * 1.3, -1.0, 1.0)
                    result = self.model.transcribe(resampled, language=LANGUAGE)
                    texts_to_add.append(result["text"])
            except Exception as e:
                texts_to_add.append(f"[æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...]")
                print(f"[ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒãƒƒãƒ•ã‚¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}]")

        # ã‚­ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        for data in queue_data:
            try:
                mono = np.mean(data, axis=1) if data.ndim > 1 else data.flatten()
                if mono.size > 0:
                    resampled = librosa.resample(mono, orig_sr=SAMPLE_RATE, target_sr=TARGET_SR)
                    resampled = np.clip(resampled * 1.3, -1.0, 1.0)
                    result = self.model.transcribe(resampled, language=LANGUAGE)
                    texts_to_add.append(result["text"])
            except Exception as e:
                texts_to_add.append(f"[æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...]")
                print(f"[ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¼å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}]")

        # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«æ–‡å­—èµ·ã“ã—çµæœã‚’æ›´æ–°
        if texts_to_add:
            with self.transcription_lock:
                if scene_name not in self.scene_transcriptions:
                    self.scene_transcriptions[scene_name] = []
                self.scene_transcriptions[scene_name].extend(texts_to_add)
                
        print(f"ã‚·ãƒ¼ãƒ³ '{scene_name}' ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")